{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jnlJvEL5YyBO"
   },
   "outputs": [],
   "source": [
    "# Práctica 8: ML US\n",
    "# LIBRERIAS NECESARIAS (si os hacen falta más, debéis añadirlas)\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from UNET import *  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6zNi5qUQiGOX",
    "outputId": "c14e7bc9-b390-4fd2-f6b1-e7d921505199"
   },
   "outputs": [],
   "source": [
    "# Folder with files path:\n",
    "folder = os.getcwd() + '/benign'\n",
    "print(folder)\n",
    "# Alphabetically ordered list:\n",
    "os.chdir(folder)\n",
    "content = os.listdir(folder)\n",
    "content.sort()\n",
    "os.chdir('..')\n",
    "\n",
    "# Remove .DS_Store file if exists:\n",
    "if content[0] == '.DS_Store':\n",
    "    content.pop(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7pM5VlYLiGOY"
   },
   "outputs": [],
   "source": [
    "# Lista de imágenes y de máscaras\n",
    "listImages = []\n",
    "for im in content:\n",
    "    listImages.append(im[:-4])\n",
    "    \n",
    "listImages = list(set(listImages))\n",
    "listImages.sort()\n",
    "\n",
    "listMasks = []\n",
    "idx = []\n",
    "for k1 in range(len(listImages)):\n",
    "    if listImages[k1][-4:] == 'mask':\n",
    "        listMasks.append(listImages[k1])\n",
    "        idx.append(k1)\n",
    "        \n",
    "    if listImages[k1][-6:-2] == 'mask':\n",
    "        listMasks.append(listImages[k1])\n",
    "        idx.append(k1)\n",
    "\n",
    "listImages = [v for i, v in enumerate(listImages) if i not in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5SKqOJYiGOZ"
   },
   "outputs": [],
   "source": [
    "# Retrieve images -> X_train_full \n",
    "X_train_full=[]\n",
    "\n",
    "# Retrieve masks -> Y_train_full \n",
    "Y_train_full=[]\n",
    "\n",
    "# Sin data augmentation, primero separaré el test\n",
    "for k1 in listImages: # k1 -> Index for list of images\n",
    "    Img = img_to_array(load_img(os.getcwd()+'/benign/'+k1+'.png', target_size=(400,400), color_mode='grayscale'))\n",
    "    X_train_full.append(np.array(Img))\n",
    "\n",
    "for k1 in range(len(listMasks)):\n",
    "    mask = img_to_array(load_img(os.getcwd()+'/benign/'+listMasks[k1]+'.png', target_size=(400,400), color_mode='grayscale'))\n",
    "    mask = mask > 0\n",
    "    \n",
    "    if listMasks[k1][-6:-2] == 'mask':\n",
    "        Y_train_full[-1] = Y_train_full[-1] | mask\n",
    "    \n",
    "    else:\n",
    "        Y_train_full.append(mask)       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cojo para test las 50 primeras imágenes y las quito de los conjuntos\n",
    "X_test = X_train_full[0:50]\n",
    "X_train_full[0:50] = []\n",
    "\n",
    "Y_test = Y_train_full[0:50]\n",
    "Y_train_full[0:50] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hago data augmentation de las imágenes\n",
    "X_dA_train_full = np.zeros((len(X_train_full)*4,400,400,1))\n",
    "index = list(range(0,len(X_dA_train_full)))\n",
    "indexImg = index[0::4]\n",
    "\n",
    "for k1 in range(len(X_train_full)):\n",
    "    X_dA_train_full[indexImg[k1]] = X_train_full[k1]\n",
    "    X_dA_train_full[indexImg[k1]+1] = np.flip(X_train_full[k1], (0, 2))\n",
    "    X_dA_train_full[indexImg[k1]+2] = np.flip(X_train_full[k1], (1, 2))\n",
    "    X_dA_train_full[indexImg[k1]+3] = np.flip(X_train_full[k1], (1, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hago data augmentation de las máscaras\n",
    "Y_dA_train_full = np.zeros((len(Y_train_full)*4,400,400,1))\n",
    "index = list(range(0,len(Y_dA_train_full)))\n",
    "indexImg = index[0::4]\n",
    "\n",
    "for k1 in range(len(Y_train_full)):\n",
    "    Y_dA_train_full[indexImg[k1]] = Y_train_full[k1]\n",
    "    Y_dA_train_full[indexImg[k1]+1] = np.flip(Y_train_full[k1], (0, 2))\n",
    "    Y_dA_train_full[indexImg[k1]+2] = np.flip(Y_train_full[k1], (1, 2))\n",
    "    Y_dA_train_full[indexImg[k1]+3] = np.flip(Y_train_full[k1], (1, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gx6bzG76iGOa"
   },
   "outputs": [],
   "source": [
    "# Separar conjuntos de entrenamiento, validacion y test\n",
    "\n",
    "# Normalizamos las imágenes de test\n",
    "for k1 in range(len(X_test)):\n",
    "\n",
    "    cropnorm = np.array(X_test[k1], dtype=np.float32)\n",
    "    \n",
    "    # Normalizamos para tener la imagen en el rango [0,1]\n",
    "    cropnorm = cropnorm - cropnorm.min() \n",
    "    cropnorm = cropnorm / cropnorm.max()\n",
    "    \n",
    "    # Almacenamos el crop normaizado\n",
    "    X_test[k1] = np.reshape(cropnorm,(400,400,1))\n",
    "    \n",
    "X_test = np.array(X_test, dtype='float32'); Y_test = np.array(Y_test, dtype='float32')\n",
    "\n",
    "\n",
    "# Normalizamos las imágenes de entrenamiento\n",
    "for k1 in range(len(X_dA_train_full)):\n",
    "\n",
    "    cropnorm = np.array(X_dA_train_full[k1], dtype=np.float32)\n",
    "    \n",
    "    # Normalizamos para tener la imagen en el rango [0,1]\n",
    "    cropnorm = cropnorm - cropnorm.min() \n",
    "    cropnorm = cropnorm / cropnorm.max()\n",
    "    \n",
    "    # Almacenamos el crop normaizado\n",
    "    X_dA_train_full[k1] = np.reshape(cropnorm,(400,400,1))\n",
    "\n",
    "np.random.seed(71)\n",
    "idxTrain = np.random.permutation(len(X_dA_train_full))\n",
    "Xt1 = np.array(X_dA_train_full, dtype=np.float32)[idxTrain,:,:,:]\n",
    "Yt1 = np.array(Y_dA_train_full, dtype=np.float32)[idxTrain,:]\n",
    "    \n",
    "th1 = int(.75*(len(Yt1)))\n",
    "\n",
    "# Generate train, validation and test sets:\n",
    "X_train = np.array(Xt1[0:th1], dtype=np.float32)\n",
    "X_valid = np.array(Xt1[th1+1:len(Xt1)], dtype=np.float32)\n",
    "Y_train = np.array(Yt1[0:th1], dtype=np.float32)\n",
    "Y_valid = np.array(Yt1[th1+1:len(Yt1)], dtype=np.float32)\n",
    "\n",
    "del Xt1, Yt1, X_train_full, X_dA_train_full, Y_dA_train_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oKKMqFU0iGOa"
   },
   "outputs": [],
   "source": [
    "# Get the UNET model you want:\n",
    "input_img = Input((400, 400, 1), name='img')\n",
    "    \n",
    "# UNET MODELS:\n",
    "model = get_unet6(input_img, n_filters=14, dropout= 0.25, batchnorm=True)\n",
    "model.compile(optimizer = Adam(learning_rate = 1e-3), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 853
    },
    "id": "OJ4XAo4jiGOb",
    "outputId": "61d82c2f-bb6b-4f69-a1ac-5a919189cadf",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Training...\n",
    "Save = True\n",
    "if Save:\n",
    "    results = model.fit(X_train, Y_train, epochs=10, validation_data=(X_valid, Y_valid))\n",
    "\n",
    "# Representation of model accuracy and model loss\n",
    "#Learning_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "It7QMuToAM9Y"
   },
   "outputs": [],
   "source": [
    "# Guardamos pesos o los cargamos\n",
    "if Save:\n",
    "    model.save_weights('UNET.h5')\n",
    "else:\n",
    "    model.load_weights('UNET.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test y comprobacion\n",
    "for k1 in range(len(X_test)):\n",
    "    plt.figure(figsize=(400,400))\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1,3)\n",
    "    ax1.imshow(X_test[k1].reshape((400,400)),cmap='gray')\n",
    "    pred = model.predict(X_test[k1].reshape((1,400,400,1)))\n",
    "    ax2.imshow(pred.reshape((400,400)), cmap='gray')\n",
    "    ax3.imshow(Y_test[k1], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo coeficiente DICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A77xe5Pi0xOt",
    "outputId": "990c59f8-9a7b-4e62-ad19-eac13f18cf33",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DICE = dice_coef(Y_test,model.predict(X_test))\n",
    "print(np.float32(DICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo coeficiente JACCARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JACCARD = jaccard_coef(Y_test,model.predict(X_test))\n",
    "print(np.float32(JACCARD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poner bien el nombre a las variables y eso\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "# Umbralizamos la prediccion de la red con un umbral muy bajo\n",
    "pred_umb = np.zeros(pred.shape)\n",
    "pred_umb[np.where(pred>0.3)] = 1\n",
    "\n",
    "(VP,VN,FP,FN) = calcula_valores(pred_umb,Y_test)\n",
    "\n",
    "Acuraccy = (VP+VN)/(VP+FP+FN+VN)\n",
    "Sensibilidad = VP/(VP+FN)\n",
    "Especificidad = VN/(VN+FP)\n",
    "VPP = VP/(VP+FP) # Valor predictivo positivo\n",
    "VPN = VN/(VN + FN) # Valor predictivo negativo\n",
    "\n",
    "print(Acuraccy)\n",
    "print(Sensibilidad)\n",
    "print(Especificidad)\n",
    "print(VPP)\n",
    "print(VPN)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "IAM_8.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9 (applemetal)",
   "language": "python",
   "name": "applemetal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
